{
  "input_model": {
    "type": "PyTorchModel",
    "model_path": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
    "io_config": {
      "input_names": [
        "input_ids",
        "attention_mask",
        "token_type_ids",
        "position_ids"
      ],
      "input_shapes": [
        [1, 512],
        [1, 1, 512, 512],
        [1, 512],
        [1, 512]
      ],
      "input_types": ["int64", "float32", "int64", "int64"],
      "output_names": ["start_logits", "end_logits"],
      "output_shapes": [
        [1, 512],
        [1, 512]
      ],
      "output_types": ["float32", "float32"],
      "dynamic_axes": {
        "input_ids": { "0": "batch_size", "1": "sequence_length" },
        "attention_mask": {
          "0": "batch_size",
          "2": "sequence_length",
          "3": "sequence_length"
        },
        "token_type_ids": { "0": "batch_size", "1": "sequence_length" },
        "position_ids": { "0": "batch_size", "1": "sequence_length" },
        "logits": { "0": "batch_size" }
      }
    },
    "model_loader": "load_model",
    "model_script": "google_bert_qdq_npu_squad.py",
    "script_dir": "."
  },
  "engine": {
    "host": "host_system",
    "target": "target_system",
    "cache_dir": "temp/cache",
    "clean_cache": true,
    "clean_evaluation_cache": true,
    "evaluator": "squad_evaluator",
    "evaluate_input_model": false,
    "output_dir": "outputs/google/bert_large_uncased_qa"
  },
  "systems": {
    "host_system": {
      "type": "LocalSystem",
      "accelerators": [
        { "device": "cpu", "execution_providers": ["CPUExecutionProvider"] }
      ]
    },
    "target_system": {
      "type": "LocalSystem",
      "accelerators": [
        { "device": "npu", "execution_providers": ["QNNExecutionProvider"] }
      ]
    }
  },
  "data_configs": [
    {
      "name": "calibration_data",
      "type": "HuggingfaceContainer",
      "load_dataset_config": {
        "data_name": "squad",
        "split": "train"
      },
      "pre_process_data_config": {
        "type": "tokenize_dataset",
        "model_name": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
        "input_cols": ["question", "context"],
        "label_col": "idx",
        "seq_length": 512,
        "max_samples": 10
      },
      "dataloader_config": { "batch_size": 1 },
      "user_script": "google_bert_qdq_npu_squad.py",
      "script_dir": "."
    },
    {
      "name": "eval_data",
      "type": "HuggingfaceContainer",
      "load_dataset_config": {
        "data_name": "squad",
        "split": "validation"
      },
      "pre_process_data_config": {
        "type": "tokenize_dataset",
        "model_name": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
        "input_cols": ["question", "context"],
        "label_col": "idx",
        "seq_length": 512,
        "max_samples": 100
      },
      "post_process_data_config": {
        "type": "bert_qa_post_process"
      },
      "dataloader_config": { "batch_size": 1 },
      "user_script": "google_bert_qdq_npu_squad.py"
    }
  ],
  "evaluators": {
    "squad_evaluator": {
      "metrics": [
        {
          "name": "eval_squad",
          "type": "custom",
          "data_config": "eval_data",
          "sub_types": [
            {
              "name": "exact_match",
              "priority": 1,
              "higher_is_better": true
            },
            { "name": "f1", "higher_is_better": true }
          ],
          "user_config": {
            "user_script": "google_bert_qdq_npu_squad.py",
            "metric_func": "eval_squad",
            "metric_func_kwargs": {
              "model_name": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
              "dataset_config": {
                "data_name": "squad",
                "split": "validation"
              },
              "seq_length": 512
            }
          }
        },
        {
          "name": "perf_latency",
          "type": "latency",
          "data_config": "eval_data",
          "warmup_num": 2,
          "repeat_test_num": 10,
          "sub_types": [
            { "name": "avg", "warmup_num": 2, "repeat_test_num": 10 },
            { "name": "p75", "warmup_num": 2, "repeat_test_num": 10 },
            { "name": "p90", "warmup_num": 2, "repeat_test_num": 10 }
          ],
          "user_config": {
            "inference_settings": {
              "onnx": {
                "execution_provider": "QNNExecutionProvider",
                "provider_options": [
                  {
                    "htp_graph_finalization_optimization_mode": 3,
                    "htp_performance_mode": "burst"
                  }
                ]
              }
            }
          }
        }
      ]
    }
  },
  "passes": {
    "conversion": {
      "device": "cpu",
      "type": "OnnxConversion",
      "target_opset": 17,
      "dynamic": true,
      "use_dynamo_exporter": false,
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    },
    "to_fixed_shape": {
      "type": "DynamicToFixedShape",
      "dim_param": ["batch_size", "sequence_length"],
      "dim_value": [1, 512],
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    },
    "qnn_preprocess": {
      "type": "QNNPreprocess",
      "fuse_layernorm": true,
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    },
    "quantization": {
      "type": "OnnxStaticQuantization",
      "data_config": "calibration_data",
      "quant_preprocess": true,
      "activation_type": "QUInt16",
      "weight_type": "QUInt8",
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    }
  }
}
